---
title: "Verfügbare LLM-Modelle abrufen"
api: "GET https://app.famulor.de/api/user/assistants/models"
icon: "brain-circuit"
description: "Alle verfügbaren LLM-Modelle für die Assistenten-Konfiguration abrufen"
---

Dieser Endpunkt gibt eine Liste aller verfügbaren Large Language Models (LLMs) zurück, die beim Erstellen oder Aktualisieren von Assistenten verwendet werden können.

### Antwort-Felder

Die API gibt ein direktes Array von verfügbaren LLM-Modellen zurück:

<ResponseField name="array" type="array">
  Array der verfügbaren LLM-Modelle

  <Expandable title="LLM-Modell-Eigenschaften">
    <ResponseField name="id" type="integer">
      Die eindeutige Kennung des LLM-Modells
    </ResponseField>

    <ResponseField name="name" type="string">
      Der Anzeigename des LLM-Modells
    </ResponseField>
  </Expandable>
</ResponseField>

### Hinweise

- Dieser Endpunkt benötigt keine Parameter
- Verwenden Sie das `name`-Feld beim Erstellen oder Aktualisieren von Assistenten
- Alle verfügbaren LLM-Modelle werden in einer einzigen Anfrage zurückgegeben
- Verschiedene Modelle können unterschiedliche Fähigkeiten, Leistung und Kostenmerkmale haben

<RequestExample>

```bash Verfügbare LLM-Modelle abrufen
curl -H "Authorization: Bearer YOUR_API_TOKEN" \
  "https://app.famulor.de/api/user/assistants/models"
```

</RequestExample>

<ResponseExample>

```json 200 Response
[
  {
    "id": 1,
    "name": "GPT-4o-mini"
  },
  {
    "id": 2,
    "name": "GPT-4.1-mini"
  },
  {
    "id": 3,
    "name": "GPT-4.1-nano"
  },
  {
    "id": 4,
    "name": "Llama 3.3 70B"
  },
  {
    "id": 5,
    "name": "Llama 4 Scout 17B"
  },
  {
    "id": 6,
    "name": "Llama 4 Maverick 17B"
  },
  {
    "id": 7,
    "name": "GPT-4o"
  },
  {
    "id": 8,
    "name": "GPT-4.1"
  },
  {
    "id": 9,
    "name": "Gemini 2.5 Pro"
  },
  {
    "id": 10,
    "name": "Gemini 2.5 Flash"
  }
]
```

</ResponseExample>
